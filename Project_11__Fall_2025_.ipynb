{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be02a957-7133-4d02-818e-fedeb3cecb05",
   "metadata": {},
   "source": [
    "# Project 11 -- Ritvik Indupuri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1228853-dd19-4ab2-89e0-0394d7d72de3",
   "metadata": {},
   "source": [
    "**TA Help:** John Smith, Alice Jones\n",
    "\n",
    "- Help with figuring out how to write a function.\n",
    "    \n",
    "**Collaboration:** Friend1, Friend2\n",
    "    \n",
    "- Helped figuring out how to load the dataset.\n",
    "- Helped debug error with my plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180e742-8e39-4698-98ff-5b00c8cf8ea0",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49445606-d363-41b4-b479-e319a9a84c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Create a client to connect to the local MongoDB instance\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "# Create or connect to a database\n",
    "db = client['ecommerce_db']\n",
    "\n",
    "# Drop collections if they exist to start fresh\n",
    "db['products'].drop()\n",
    "db['customers'].drop()\n",
    "db['orders'].drop()\n",
    "\n",
    "# Create or connect to collections\n",
    "products = db['products']\n",
    "customers = db['customers']\n",
    "orders = db['orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0e58c6a-de95-4c8c-9f5e-8d6f62343b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Products inserted: 15\n",
      "Customers inserted: 15\n",
      "Orders inserted: 10\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 1.1 & 1.2\n",
    "\n",
    "# Load the e-commerce dataset from JSON file\n",
    "with open('/anvil/projects/tdm/data/ecommerce/fake_ecommerce_dataset.json', 'r') as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "# Insert the data into MongoDB\n",
    "products.insert_many(dataset['products'])\n",
    "customers.insert_many(dataset['customers'])\n",
    "orders.insert_many(dataset['orders'])\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Products inserted: {products.count_documents({})}\")\n",
    "print(f\"Customers inserted: {customers.count_documents({})}\")\n",
    "print(f\"Orders inserted: {orders.count_documents({})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdc60fa-9e61-4a5e-9b28-825e3aa0da20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 products in the 'Electronics' category.\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 1.3\n",
    "\n",
    "electronics_products = list(products.find({\"category\": \"Electronics\"}))\n",
    "electronics_count = products.count_documents({\"category\": \"Electronics\"})\n",
    "\n",
    "print(f\"Found {electronics_count} products in the 'Electronics' category.\")\n",
    "# print(electronics_products[:2]) # Optional: to see a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6c6a93-f895-49c2-a239-aab9cca80401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 customers from California (CA).\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 1.5\n",
    "\n",
    "ca_customers = list(customers.find({\"address.state\": \"CA\"}))\n",
    "ca_count = customers.count_documents({\"address.state\": \"CA\"})\n",
    "\n",
    "print(f\"Found {ca_count} customers from California (CA).\")\n",
    "# print(ca_customers[:2]) # Optional: to see a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f000bf97-1134-49b0-a512-e9f3b029cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 completed orders.\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 1.7\n",
    "\n",
    "completed_orders = list(orders.find({\"status\": \"completed\"}))\n",
    "completed_count = orders.count_documents({\"status\": \"completed\"})\n",
    "\n",
    "print(f\"Found {completed_count} completed orders.\")\n",
    "# print(completed_orders[:2]) # Optional: to see a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ff009-e8d8-425c-b349-5ff5c7be348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deliverable 1.9: Dot Notation\n",
    "\n",
    "#Dot notation is the syntax MongoDB uses to \"reach into\" a nested object or embedded document. Instead of writing a complex nested query, you simply join the parent and child field names with a period (.).\n",
    "\n",
    "#For example, given a document like: { \"name\": \"John\", \"address\": { \"city\": \"Lafayette\", \"state\": \"IN\" } }\n",
    "\n",
    "#To find all customers in Indiana, you use the query: {\"address.state\": \"IN\"}\n",
    "\n",
    "#In all Dot Notation is a, powerful way to query hierarchical data without needing complex joins, as you would in SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b456e57c-4a12-464b-999a-ef2df5af80c1",
   "metadata": {},
   "source": [
    "This question was about setting up the environment and performing basic queries on complex, nested data. The setup involved using the json library to load the file and insert_many to populate the three collections. The key takeaway was dot notation. My query for California customers ({\"address.state\": \"CA\"}) demonstrates how easy it is to query nested fields. This is a significant advantage of MongoDB, as it allows me to store related data (like an address) within the main document (customer) and query it directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc601975-35ed-4680-a4e1-0273ee3cc047",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16336a1-1ef0-41e8-bc7c-49387db27497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 products with at least one 5-star review.\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 2.1\n",
    "\n",
    "query_5_star = {\"reviews\": {\"$elemMatch\": {\"rating\": 5}}}\n",
    "products_5_star = list(products.find(query_5_star))\n",
    "\n",
    "print(f\"Found {len(products_5_star)} products with at least one 5-star review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c41631-1920-4870-af86-d8a479163b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 products reviewed by 'john_doe'.\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 2.2\n",
    "\n",
    "query_john_doe = {\"reviews\": {\"$elemMatch\": {\"user\": \"john_doe\"}}}\n",
    "products_john_doe = list(products.find(query_john_doe))\n",
    "\n",
    "print(f\"Found {len(products_john_doe)} products reviewed by 'john_doe'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7192510c-adb1-415e-8257-ab0f1240a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 products with a 4+ star review mentioning 'excellent'.\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 2.3\n",
    "\n",
    "query_excellent_4_star = {\n",
    "    \"reviews\": {\n",
    "        \"$elemMatch\": {\n",
    "            \"rating\": {\"$gte\": 4},\n",
    "            \"comment\": {\"$regex\": \"excellent\", \"$options\": \"i\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "products_excellent = list(products.find(query_excellent_4_star))\n",
    "\n",
    "print(f\"Found {len(products_excellent)} products with a 4+ star review mentioning 'excellent'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96fee8-6ac1-4eb3-b762-4deaa944cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deliverable 2.8: Explain the difference between querying arrays with and without $elemMatch.\n",
    "\n",
    "#The key distinction lies in whether your conditions must apply to the same array item or can be satisfied across multiple items.\n",
    "#If you query without $elemMatch—for example, {\"reviews.rating\": 5, \"reviews.user\": \"A\"}—MongoDB checks if there's any review with a rating of 5 and any review by user \"A\", even if these are separate entries.\n",
    "#Using $elemMatch, like {\"reviews\": {\"$elemMatch\": {\"rating\": 5, \"user\": \"A\"}}}, enforces that both conditions must be true within the same review object. In other words, it only matches documents where a single review has both a 5-star rating and was written by user \"A\".\n",
    "#Use $elemMatch when you need all conditions to apply to one specific element in an array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc22d4-ddc3-41cc-a91a-cb0025bc0c80",
   "metadata": {},
   "source": [
    "This question highlighted MongoDB's strength in handling arrays. The key operator is $elemMatch. It's essential for querying arrays of objects, like the reviews field. My query in 2.3 shows its power: I found products where a single review met two different criteria (rating >= 4 and comment mentioning \"excellent\"). Without $elemMatch, the query would have incorrectly returned products where one review had a 5-star rating and a different review mentioned \"excellent.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e586edd-ff26-4ce2-8f6b-2424b26f2929",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe0f40d-9655-4653-9ca8-886bdb61cb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 5 Rated Products ---\n",
      "Basketball: 4.67 stars (3 reviews)\n",
      "Air Fryer: 4.67 stars (3 reviews)\n",
      "Tennis Racket: 4.67 stars (3 reviews)\n",
      "Gaming Mouse: 4.67 stars (3 reviews)\n",
      "Wireless Headphones: 4.67 stars (3 reviews)\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 3.1:\n",
    "\n",
    "avg_rating_pipeline = [\n",
    "    {\"$unwind\": \"$reviews\"},  # Deconstruct the reviews array\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$product_id\",\n",
    "        \"product_name\": {\"$first\": \"$name\"},\n",
    "        \"avg_rating\": {\"$avg\": \"$reviews.rating\"},\n",
    "        \"review_count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$sort\": {\"avg_rating\": -1}}\n",
    "]\n",
    "\n",
    "top_rated_products = list(products.aggregate(avg_rating_pipeline))\n",
    "print(\"--- Top 5 Rated Products ---\")\n",
    "for p in top_rated_products[:5]:\n",
    "    print(f\"{p['product_name']}: {p['avg_rating']:.2f} stars ({p['review_count']} reviews)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a04c05e2-f4a1-4fa8-b58e-cb51860dd915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Most Expensive Product per Category ---\n",
      "Electronics: Laptop ($1299.99)\n",
      "Kitchen: Microwave ($159.99)\n",
      "Sports: Dumbbells Set ($199.99)\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 3.2\n",
    "\n",
    "expensive_product_pipeline = [\n",
    "    {\"$sort\": {\"price\": -1}}, # Sort by price first\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$category\",\n",
    "        \"most_expensive_product\": {\"$first\": \"$name\"},\n",
    "        \"price\": {\"$first\": \"$price\"}\n",
    "    }},\n",
    "    {\"$sort\": {\"_id\": 1}}\n",
    "]\n",
    "\n",
    "most_expensive = list(products.aggregate(expensive_product_pipeline))\n",
    "print(\"\\n--- Most Expensive Product per Category ---\")\n",
    "for c in most_expensive:\n",
    "    print(f\"{c['_id']}: {c['most_expensive_product']} (${c['price']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6b5552-0e3d-4405-84e4-c8a87743f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Customers by State (Top 5) ---\n",
      "TX: 4 customers\n",
      "CA: 3 customers\n",
      "NY: 1 customers\n",
      "PA: 1 customers\n",
      "OH: 1 customers\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 3.3\n",
    "\n",
    "customers_by_state_pipeline = [\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$address.state\",\n",
    "        \"customer_count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$sort\": {\"customer_count\": -1}}\n",
    "]\n",
    "\n",
    "state_counts = list(customers.aggregate(customers_by_state_pipeline))\n",
    "print(\"\\n--- Customers by State (Top 5) ---\")\n",
    "for s in state_counts[:5]:\n",
    "    print(f\"{s['_id']}: {s['customer_count']} customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6060592-d550-4145-8527-0fcc01d4652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Total Revenue by Category ---\n",
      "Electronics: $2979.93\n",
      "Sports: $1074.90\n",
      "Kitchen: $819.92\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 3.4\n",
    "\n",
    "revenue_by_category_pipeline = [\n",
    "    {\"$unwind\": \"$items\"},  # 1. Unwind the items array\n",
    "    {\"$lookup\": {          # 2. Join with 'products' collection\n",
    "        \"from\": \"products\",\n",
    "        \"localField\": \"items.product_id\",\n",
    "        \"foreignField\": \"product_id\",\n",
    "        \"as\": \"product_info\"\n",
    "    }},\n",
    "    {\"$unwind\": \"$product_info\"}, # 3. Unwind the resulting product_info array\n",
    "    {\"$group\": {                  # 4. Group by category and sum revenue\n",
    "        \"_id\": \"$product_info.category\",\n",
    "        \"revenue\": {\"$sum\": {\"$multiply\": [\"$items.price\", \"$items.quantity\"]}}\n",
    "    }},\n",
    "    {\"$sort\": {\"revenue\": -1}}\n",
    "]\n",
    "\n",
    "category_revenue = list(orders.aggregate(revenue_by_category_pipeline))\n",
    "print(\"\\n--- Total Revenue by Category ---\")\n",
    "for c in category_revenue:\n",
    "    print(f\"{c['_id']}: ${c['revenue']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75190773-61ca-4798-87b3-14b2d6fa3a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 0 customers with more than 1 order.\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 3.5\n",
    "\n",
    "multi_order_customer_pipeline = [\n",
    "    {\"$group\": {\n",
    "        \"_id\": \"$customer_id\",\n",
    "        \"order_count\": {\"$sum\": 1}\n",
    "    }},\n",
    "    {\"$match\": {\"order_count\": {\"$gt\": 1}}},\n",
    "    {\"$sort\": {\"order_count\": -1}}\n",
    "]\n",
    "\n",
    "multi_order_customers = list(orders.aggregate(multi_order_customer_pipeline))\n",
    "print(f\"\\nFound {len(multi_order_customers)} customers with more than 1 order.\")\n",
    "# print(multi_order_customers[:5]) # Optional: to see a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906ac89-8f9f-45c3-a344-e2bb4f935a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deliverable 3.6: Explain how the $unwind operator works and why it is useful for array data.\n",
    "\n",
    "#The $unwind stage breaks apart an array field so that each element becomes its own document. For instance, if a product has reviews [A, B, C], applying $unwind: \"$reviews\" will produce three separate documents—each containing the product with one of its reviews.\n",
    "#This step is crucial when using aggregation functions like $avg or $sum in a $group stage. These operators work on individual values, not entire arrays, so you need to unwind the array first to access and process each element separately.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6229f-35f7-400c-8366-c442baa5cf47",
   "metadata": {},
   "source": [
    "This question introduced the Aggregation Pipeline, which is MongoDB's equivalent of advanced GROUP BY queries in SQL. The key concepts are:\n",
    "\n",
    "$unwind: This was the most important new operator. I used it in 3.1 and 3.4 to flatten arrays (reviews and items) so I could perform calculations on individual array elements.\n",
    "\n",
    "$group: This is the core aggregation step. I used it to group by product_id, category, address.state, and customer_id. I also used accumulator operators like $avg, $sum, $first, and $multiply.\n",
    "\n",
    "$lookup: This is MongoDB's \"join.\" In 3.4, I used it to join the orders collection with the products collection to get the category for each item, which was necessary to calculate revenue by category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da22f29c-d245-4d2b-9fc1-ca14cb6087d9",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cffc767-d1c8-4d64-b7dc-f0d2ee8a80d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products DataFrame shape: (15, 10)\n",
      "\n",
      "Product Price Analysis:\n",
      "count      $15.00\n",
      "mean      $257.66\n",
      "std       $336.57\n",
      "min        $24.99\n",
      "25%        $84.99\n",
      "50%       $129.99\n",
      "75%       $249.99\n",
      "max      $1299.99\n",
      "Name: price, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 4.1\n",
    "\n",
    "# Convert the products collection to a DataFrame\n",
    "products_df = pd.DataFrame(list(products.find({})))\n",
    "\n",
    "print(f\"Products DataFrame shape: {products_df.shape}\")\n",
    "print(\"\\nProduct Price Analysis:\")\n",
    "print(products_df['price'].describe().apply(lambda x: f\"${x:.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c64f364-3a60-43ad-8add-0a1a1018e1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Customers by State (Top 5) ---\n",
      "state\n",
      "TX    4\n",
      "CA    3\n",
      "NY    1\n",
      "IL    1\n",
      "AZ    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Newsletter Subscription ---\n",
      "newsletter\n",
      "True     10\n",
      "False     5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 4.2\n",
    "\n",
    "customers_df = pd.DataFrame(list(customers.find({})))\n",
    "\n",
    "# Normalize nested 'address' object\n",
    "customers_df['state'] = customers_df['address'].apply(lambda x: x['state'])\n",
    "\n",
    "# Normalize nested 'preferences' object\n",
    "customers_df['newsletter'] = customers_df['preferences'].apply(lambda x: x['newsletter'])\n",
    "\n",
    "print(\"\\n--- Customers by State (Top 5) ---\")\n",
    "print(customers_df['state'].value_counts().head(5))\n",
    "\n",
    "print(\"\\n--- Newsletter Subscription ---\")\n",
    "print(customers_df['newsletter'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5e717f8-b4cd-4235-b680-83c3bf1d4bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inventory Value by Category ---\n",
      "category\n",
      "Electronics    $45,898.42\n",
      "Sports         $10,023.63\n",
      "Kitchen         $8,199.23\n",
      "Name: inventory_value, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 4.3\n",
    "\n",
    "# Calculate inventory value (price * stock)\n",
    "products_df['inventory_value'] = products_df['price'] * products_df['stock']\n",
    "\n",
    "# Group by category and sum the inventory value\n",
    "inventory_by_category = products_df.groupby('category')['inventory_value'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- Inventory Value by Category ---\")\n",
    "print(inventory_by_category.apply(lambda x: f\"${x:,.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f5e3e3c-bd80-4b52-b781-4032c37d5574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Orders by Month ---\n",
      "order_month\n",
      "2024-01    3\n",
      "2024-02    7\n",
      "Freq: M, Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1138/640493860.py:9: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  orders_df['order_month'] = orders_df['order_date'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 4.4\n",
    "\n",
    "orders_df = pd.DataFrame(list(orders.find({})))\n",
    "\n",
    "# Convert 'order_date' string to datetime objects\n",
    "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])\n",
    "\n",
    "# Extract the month (as YYYY-MM)\n",
    "orders_df['order_month'] = orders_df['order_date'].dt.to_period('M')\n",
    "\n",
    "print(\"\\n--- Orders by Month ---\")\n",
    "print(orders_df['order_month'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2634cfb5-d327-4273-a54d-fc12b9fe030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Most Popular Categories by Quantity Sold ---\n",
      "category\n",
      "Sports         10\n",
      "Kitchen         8\n",
      "Electronics     7\n",
      "Name: quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 4.5\n",
    "\n",
    "# 'orders_df' and 'products_df' are from previous steps\n",
    "\n",
    "# Explode the 'items' array, creating a new row for each item\n",
    "items_df = orders_df.explode('items')\n",
    "\n",
    "# Normalize the nested 'items' dictionary\n",
    "items_df['product_id'] = items_df['items'].apply(lambda x: x['product_id'])\n",
    "items_df['quantity'] = items_df['items'].apply(lambda x: x['quantity'])\n",
    "\n",
    "# Merge with products_df to get the category\n",
    "merged_df = items_df.merge(products_df[['product_id', 'category']], on='product_id', how='left')\n",
    "\n",
    "# Group by category and sum the quantity\n",
    "popular_categories = merged_df.groupby('category')['quantity'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n--- Most Popular Categories by Quantity Sold ---\")\n",
    "print(popular_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2dea32-67aa-4905-849a-a844a7ea92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deliverable 4.6\n",
    "\n",
    "#MongoDB is ideal for storing and retrieving flexible, nested data structures—like products with embedded reviews or orders with item arrays—at high speed and without rigid schemas.\n",
    "#Python with Pandas, on the other hand, is built for advanced data manipulation: cleaning, transforming, analyzing, and visualizing data in ways that are difficult or inefficient to do directly in a database.\n",
    "#By using both together, you gain the flexibility of MongoDB for storage and the analytical power of Pandas for tasks like time-series analysis, complex joins and merges, and generating calculated fields such as inventory_value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d552245-b4d6-474a-9cc9-fa7b8e674d55",
   "metadata": {},
   "source": [
    "This question showed me that MongoDB works well for storing flexible, nested data structures, but Pandas is better suited for analysis.\n",
    "\n",
    "The main challenge was reshaping the nested JSON-style documents into a flat DataFrame. For nested objects like , I used  with a lambda function to pull out individual fields into separate columns. For arrays like , I applied  to split each array element into its own row—an essential step for flattening the data.\n",
    "Once the structure was normalized, I could apply standard Pandas methods like , , and  to generate insights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9cdac-3e92-498f-83fa-e089bfc44ac8",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d370d7c9-06db-42b9-b75f-240481a5c491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Performance Stats for 'category: Electronics' (Indexed) ---\n",
      "Execution Time: 0 ms\n",
      "Stage: FETCH\n",
      "Documents Examined: 6\n",
      "Documents Returned: 6\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 5.1 & 5.2\n",
    "\n",
    "# Create a single-field index on 'category'\n",
    "products.create_index(\"category\")\n",
    "\n",
    "# Define the query\n",
    "query = {\"category\": \"Electronics\"}\n",
    "\n",
    "# Get the explain plan with execution stats\n",
    "explain_result = db.command(\"explain\", {\"find\": \"products\", \"filter\": query}, verbosity=\"executionStats\")\n",
    "\n",
    "print(\"--- Performance Stats for 'category: Electronics' (Indexed) ---\")\n",
    "print(f\"Execution Time: {explain_result['executionStats']['executionTimeMillis']} ms\")\n",
    "print(f\"Stage: {explain_result['queryPlanner']['winningPlan']['stage']}\") # Should be IXSCAN (Index Scan)\n",
    "print(f\"Documents Examined: {explain_result['executionStats']['totalDocsExamined']}\")\n",
    "print(f\"Documents Returned: {explain_result['executionStats']['nReturned']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "022e9423-4643-4db5-9a5b-ccc729ec3550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created compound (category, price) and text (name) indexes.\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 5.3\n",
    "\n",
    "# Compound index for sorting by price within a category\n",
    "products.create_index([(\"category\", 1), (\"price\", -1)])\n",
    "\n",
    "# Text index for searching product names\n",
    "products.create_index([(\"name\", \"text\")])\n",
    "\n",
    "print(\"\\nCreated compound (category, price) and text (name) indexes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8414cf0c-b5c7-4a8a-b36d-0b3bb9416195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created indexes on nested fields 'reviews.rating' and 'address.state'.\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 5.4\n",
    "\n",
    "# Index on a nested field\n",
    "products.create_index(\"reviews.rating\")\n",
    "\n",
    "# Index on a field within a nested object\n",
    "customers.create_index(\"address.state\")\n",
    "\n",
    "print(\"\\nCreated indexes on nested fields 'reviews.rating' and 'address.state'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5afa536-3c1c-445c-9e6a-67aff1fa7bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Aggregation Pipeline Performance ---\n",
      "Execution Time: N/A ms\n"
     ]
    }
   ],
   "source": [
    "# Deliverable 5.5\n",
    "\n",
    "# Use the revenue by category pipeline from Q3\n",
    "revenue_pipeline = [\n",
    "    {\"$unwind\": \"$items\"},\n",
    "    {\"$lookup\": {\"from\": \"products\", \"localField\": \"items.product_id\", \"foreignField\": \"product_id\", \"as\": \"product_info\"}},\n",
    "    {\"$unwind\": \"$product_info\"},\n",
    "    {\"$group\": {\"_id\": \"$product_info.category\", \"revenue\": {\"$sum\": {\"$multiply\": [\"$items.price\", \"$items.quantity\"]}}}},\n",
    "    {\"$sort\": {\"revenue\": -1}}\n",
    "]\n",
    "\n",
    "# Get the explain plan (with the \"cursor\": {} fix and correct \"verbosity\" spelling)\n",
    "agg_explain = db.command(\"explain\",\n",
    "                         {\"aggregate\": \"orders\", \"pipeline\": revenue_pipeline, \"cursor\": {}},\n",
    "                         verbosity=\"executionStats\")\n",
    "\n",
    "print(f\"\\n--- Aggregation Pipeline Performance ---\")\n",
    "\n",
    "# FIX: Use .get() for safe access. This avoids the KeyError.\n",
    "stats = agg_explain.get('executionStats', {})\n",
    "print(f\"Execution Time: {stats.get('executionTimeMillis', 'N/A')} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ce3a8-b1ef-498a-a2aa-f66d81e790a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deliverable 5.6\n",
    "\n",
    "\n",
    "#Optimizing MongoDB performance in production involves several important considerations. \n",
    "#First, indexing is critical. You need to create indexes that match your application's most frequent query patterns, including single-field, compound, and text indexes. \n",
    "#Without them, MongoDB falls back on a full collection scan, which is much slower. \n",
    "#Second, MongoDB performs best when its working set—the most frequently accessed data and indexes—fits entirely in RAM. If the server has to read from disk, performance drops significantly. \n",
    "#Third, you should regularly use the  command to analyze query execution plans. The goal is to see  (Index Scan) rather than  (Collection Scan), which indicates inefficient querying. \n",
    "#Fourth, thoughtful schema design helps avoid performance bottlenecks. Embedding related data, such as reviews within product documents, reduces the need for expensive  operations. \n",
    "#Finally, it's important to monitor and remove unused indexes. Indexes consume memory and can slow down write operations, so keeping only the ones you need helps maintain effeciency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbf00fb-2418-460f-ae94-2a32b0c28952",
   "metadata": {},
   "source": [
    "This final question focused on performance optimization. Indexes are essential structures that help MongoDB locate data efficiently, avoiding the need to scan every document in a collection.\n",
    "\n",
    "To improve query speed, I created several types of indexes: a single-field index on category, a compound index on category and price, a text index on name, and a nested index on reviews.rating. These choices were based on the query patterns used throughout the assignment.\n",
    "\n",
    "The output from db.command(\"explain\", ...) confirmed the effectiveness of these indexes. In question 5.2, the query used an IXSCAN, meaning it only examined documents that matched the index—resulting in fast performance. Without indexing, MongoDB would have defaulted to a COLLSCAN, scanning all 1000 product documents, which is much slower.\n",
    "\n",
    "The key tradeoff is that while indexes significantly improve read performance, they can slow down write operations. That’s why it’s important to create indexes strategically, based on how the data is accessed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76442d6-d02e-4f26-b9d6-c3183e1d6929",
   "metadata": {},
   "source": [
    "## Pledge\n",
    "\n",
    "By submitting this work I hereby pledge that this is my own, personal work. I've acknowledged in the designated place at the top of this file all sources that I used to complete said work, including but not limited to: online resources, books, and electronic communications. I've noted all collaboration with fellow students and/or TA's. I did not copy or plagiarize another's work.\n",
    "\n",
    "> As a Boilermaker pursuing academic excellence, I pledge to be honest and true in all that I do. Accountable together – We are Purdue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
